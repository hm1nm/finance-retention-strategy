{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10a7619",
   "metadata": {},
   "source": [
    "# ê¸°ìš¸ê¸° í˜•ì„± ë¡œì§ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b140a",
   "metadata": {},
   "source": [
    "## 6ê°œì›” ì „ì²´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íƒ€ê²Ÿ í˜•ì„±\n",
    "- 12ì›” ë°ì´í„°ì—ë§Œ ê¸°ìš¸ê¸° ì ìˆ˜ê°€ ë¶€ì—¬\n",
    "- ë‚˜ë¨¸ì§€ëŠ” ê¸°ìš¸ê¸° ì ìˆ˜ê°€ 0ìœ¼ë¡œ ë‚˜ì™€ì„œ ì´ìŠˆ ë°œìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 4925 entries, ë°œê¸‰íšŒì›ë²ˆí˜¸ to í˜œíƒìˆ˜í˜œìœ¨_B0M_12\n",
      "dtypes: float64(1467), int64(3271), object(187)\n",
      "memory usage: 1.8+ GB\n",
      "------------------------------\n",
      "Target\n",
      "0    0.94738\n",
      "1    0.05262\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ê¸°ì´ˆ ë³‘í•©\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "path_approval = './ì¹´ë“œìŠ¹ì¸ì •ë³´_WideFormat_50000_2569.csv'\n",
    "path_balance = './ì¹´ë“œì”ì•¡ì •ë³´_WideFormat_50000_487.csv'\n",
    "\n",
    "months_6m = ['07', '08', '09', '10', '11', '12']\n",
    "months_3m = ['10', '11', '12']\n",
    "\n",
    "# ìŠ¹ì¸ì •ë³´ ë¡œë“œ\n",
    "cols_app = ['ë°œê¸‰íšŒì›ë²ˆí˜¸'] + [f'ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M_{m}' for m in months_6m] + [f'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_{m}' for m in months_6m]\n",
    "df_app = pd.read_csv(path_approval, usecols=lambda x: x in cols_app).fillna(0)\n",
    "\n",
    "# ì”ì•¡ì •ë³´ ë¡œë“œ\n",
    "df_bal_raw = pd.read_csv(path_balance)\n",
    "cols_bal = ['ë°œê¸‰íšŒì›ë²ˆí˜¸'] + [f'ì”ì•¡_B0M_{m}' for m in months_6m] + [f'ì”ì•¡_í˜„ê¸ˆì„œë¹„ìŠ¤_B0M_{m}' for m in months_6m] + \\\n",
    "           [f'ì”ì•¡_ì¹´ë“œë¡ _B0M_{m}' for m in months_6m] + [f'ì—°ì²´ì”ì•¡_B0M_{m}' for m in months_6m] + [f'ì›”ì¤‘í‰ì”_{m}' for m in months_6m]\n",
    "exist_bal = [c for c in cols_bal if c in df_bal_raw.columns]\n",
    "df_bal = df_bal_raw[exist_bal].fillna(0)\n",
    "\n",
    "df_score = pd.merge(df_app, df_bal, on='ë°œê¸‰íšŒì›ë²ˆí˜¸', how='inner')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ì ìˆ˜ ë° íƒ€ê²Ÿ(Target) ìƒì„± ë¡œì§\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# ìƒíƒœ ì ìˆ˜ ê³„ì‚°\n",
    "df_score['Score_BadDebt'] = (((df_score['ì”ì•¡_í˜„ê¸ˆì„œë¹„ìŠ¤_B0M_12'] - df_score['ì”ì•¡_í˜„ê¸ˆì„œë¹„ìŠ¤_B0M_11']) / (df_score['ì”ì•¡_í˜„ê¸ˆì„œë¹„ìŠ¤_B0M_11'] + 1) * 1.5) +\n",
    "                            ((df_score['ì”ì•¡_ì¹´ë“œë¡ _B0M_12'] - df_score['ì”ì•¡_ì¹´ë“œë¡ _B0M_11']) / (df_score['ì”ì•¡_ì¹´ë“œë¡ _B0M_11'] + 1) * 1.0))\n",
    "df_score['Score_Delinq'] = (df_score['ì—°ì²´ì”ì•¡_B0M_12'] * 3.0) + (df_score['ì—°ì²´ì”ì•¡_B0M_11'] * 2.0) + (df_score['ì—°ì²´ì”ì•¡_B0M_10'] * 1.0)\n",
    "df_score['Score_Activity'] = ((df_score[[f'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_{m}' for m in months_3m]].sum(axis=1) * 2) - \n",
    "                               df_score[[f'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_{m}' for m in months_6m]].sum(axis=1)) / \\\n",
    "                              (df_score[[f'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_{m}' for m in months_6m]].sum(axis=1) + 1) * 100\n",
    "df_score['Score_Asset'] = (df_score[[f'ì›”ì¤‘í‰ì”_{m}' for m in months_3m if f'ì›”ì¤‘í‰ì”_{m}' in df_score.columns]].mean(axis=1) / \\\n",
    "                           (df_score[[f'ì›”ì¤‘í‰ì”_{m}' for m in months_6m if f'ì›”ì¤‘í‰ì”_{m}' in df_score.columns]].mean(axis=1) + 1)) * 10\n",
    "df_score['Score_Status_Total'] = (df_score['Score_BadDebt'] + df_score['Score_Delinq']) - (df_score['Score_Activity'] + df_score['Score_Asset'])\n",
    "\n",
    "# ê¸°ìš¸ê¸° ì ìˆ˜ ê³„ì‚°\n",
    "def get_slope(row, prefix):\n",
    "    cols = [f\"{prefix}_{m}\" for m in months_6m]\n",
    "    y = row[cols].values.astype(float)\n",
    "    if np.sum(y) == 0: return 0\n",
    "    return linregress(np.arange(len(y)), y)[0]\n",
    "\n",
    "df_score['Slope_Spend'] = df_score.apply(lambda r: get_slope(r, 'ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M'), axis=1)\n",
    "df_score['Slope_Balance'] = df_score.apply(lambda r: get_slope(r, 'ì”ì•¡_B0M'), axis=1)\n",
    "df_score['Slope_Count'] = df_score.apply(lambda r: get_slope(r, 'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M'), axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "def norm_risk(s):\n",
    "    risk = s.apply(lambda x: -x if x < 0 else 0)\n",
    "    return scaler.fit_transform(risk.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "df_score['Score_Slope_Total'] = (norm_risk(df_score['Slope_Spend']) * 40 + norm_risk(df_score['Slope_Balance']) * 30 + norm_risk(df_score['Slope_Count']) * 30)\n",
    "df_score['Final_Total_Score'] = (df_score['Score_Status_Total'].fillna(0) + df_score['Score_Slope_Total'].fillna(0)) * 0.5\n",
    "\n",
    "# Risk_Count ê¸°ë°˜ íƒ€ê²Ÿ ì •ì˜\n",
    "df_le0 = df_score[(df_score['Slope_Spend'] <= 0) & (df_score['Slope_Balance'] <= 0) & (df_score['Slope_Count'] <= 0)].copy()\n",
    "df_le0['Risk_Count'] = (df_le0[['Score_BadDebt', 'Score_Delinq']].gt(0).sum(axis=1) + \n",
    "                        df_le0['Score_Activity'].lt(0).astype(int) + \n",
    "                        df_le0['Score_Asset'].eq(0).astype(int))\n",
    "\n",
    "churn_list = df_le0[df_le0['Risk_Count'] >= 2]['ë°œê¸‰íšŒì›ë²ˆí˜¸'].unique()\n",
    "df_score['Target'] = 0\n",
    "df_score.loc[df_score['ë°œê¸‰íšŒì›ë²ˆí˜¸'].isin(churn_list), 'Target'] = 1\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì›ë³¸ ì „ì²´ ë°ì´í„° ë³‘í•© ë° ìµœì¢… í™•ì¸\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "path_raw = './50k_wideformat_all_50000_4921.csv'\n",
    "df_raw = pd.read_csv(path_raw, low_memory=False)\n",
    "\n",
    "# ë³‘í•© ì‹œ Target ì»¬ëŸ¼ ì¤‘ë³µìœ¼ë¡œ ì¸í•œ Target_x ë°œìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ \n",
    "# ì›ë³¸ ë°ì´í„°ì— Target ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ë¯¸ë¦¬ ì œê±°í•¨\n",
    "if 'Target' in df_raw.columns:\n",
    "    df_raw = df_raw.drop(columns=['Target'])\n",
    "\n",
    "# ìŠ¤ì½”ì–´ ë°ì´í„°ì™€ ì›ë³¸ ë°ì´í„° ë³‘í•©\n",
    "df_final = pd.merge(df_score[['ë°œê¸‰íšŒì›ë²ˆí˜¸', 'Final_Total_Score', 'Score_Status_Total', 'Score_Slope_Total', 'Target']], \n",
    "                     df_raw, \n",
    "                     on='ë°œê¸‰íšŒì›ë²ˆí˜¸', \n",
    "                     how='inner')\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ (ì´ì œ 'Target' ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ)\n",
    "print(\"âœ… ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ\")\n",
    "df_final.info()\n",
    "print(\"-\" * 30)\n",
    "print(df_final['Target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ada6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------\n",
    "# # 4. ìµœì¢… ë°ì´í„°ì…‹ CSV íŒŒì¼ ì €ì¥\n",
    "# # ---------------------------------------------------------\n",
    "\n",
    "# # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ utf-8-sig ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ë©°, ì¸ë±ìŠ¤ëŠ” ì œì™¸í•˜ê³  ì €ì¥í•¨\n",
    "# df_final.to_csv('Target_data_ì‚°ì¶œ.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b83fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    0.94738\n",
       "1    0.05262\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_final['Target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c587f20",
   "metadata": {},
   "source": [
    "## ìˆ˜ì •ëœ íƒ€ê²Ÿ\n",
    "- ê¸°ìš¸ê¸° ìˆ˜ì •\n",
    "    - ê¸°ì¡´ 6ê°œì›”ì„ ë‹¤ ì“°ëŠ” ê¸°ìš¸ê¸°ê°€ ì•„ë‹ˆë¼, ëˆ„ì  ê¸°ìš¸ê¸° + 7ì›” ë°ì´í„°ëŠ” R12M(1ë…„ ëˆ„ì ë°ì´í„°) ì»¬ëŸ¼ì„ ì´ìš©í•´ì„œ ê¸°ìš¸ê¸° ì ìˆ˜ ë¶€ì—¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94339a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Info] íŒŒì¼ ë¡œë“œ ë° ë¶„ì„ ì‹œì‘: ../../../260108/general_combined_part1.csv\n",
      " - ê³ ê°ë³„ Rolling Analysis ì§„í–‰ ì¤‘... (ë°ì´í„° ìµœì†Œ 1ê°œì›” ê¸°ì¤€, 1ê°œì›” ì‹œ R12M ë³´ì™„)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_14832\\2085201135.py:75: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  activity_score = ((sum_r3 * 2) - sum_r6) / (sum_r6 + 1) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“Š ì´íƒˆì Rolling ë¶„ì„ ê²°ê³¼ (ëŒ€ìƒ íŒŒì¼: general_combined_part1.csv)\n",
      "==================================================\n",
      " - ì´ ë¶„ì„ ê³ ê° ìˆ˜: 84000ëª…\n",
      " - ìµœì¢… ì‹œì  ì´íƒˆì ìˆ˜: 33455ëª… (39.83%)\n",
      "------------------------------\n",
      " [ì´íƒˆ ì§•í›„ ì§€ì† ê¸°ê°„ í†µê³„]\n",
      "count    33455.000000\n",
      "mean         2.197459\n",
      "std          1.617552\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          6.000000\n",
      "Name: Churn_Duration_Months, dtype: float64\n",
      "------------------------------\n",
      " [ê¸°ê°„ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)]\n",
      "Churn_Duration_Months\n",
      "6     2872\n",
      "5     1934\n",
      "4     1438\n",
      "3     3083\n",
      "2     7485\n",
      "1    16643\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… ìƒì„¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: churn_duration_results_general_combined_part1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "import tqdm  # For progress bar if available, else standard print\n",
    "\n",
    "# =============================================================================\n",
    "# [ì„¤ì •] ì»¬ëŸ¼ëª… ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "# =============================================================================\n",
    "COL_ID = 'ë°œê¸‰íšŒì›ë²ˆí˜¸'\n",
    "COL_DATE = 'ê¸°ì¤€ë…„ì›”'\n",
    "\n",
    "# ë¶„ì„ ë³€ìˆ˜ (Wide Formatì˜ ì ‘ë¯¸ì‚¬ '_MM' ë“±ì„ ë—€ ìˆœìˆ˜ ì»¬ëŸ¼ëª… ê°€ì •)\n",
    "COL_SPEND = 'ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M'      # ì†Œë¹„\n",
    "COL_COUNT = 'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M'      # ë¹ˆë„\n",
    "COL_BALANCE = 'ì”ì•¡_B0M'             # ì”ì•¡\n",
    "COL_CASH_ADV = 'ì”ì•¡_í˜„ê¸ˆì„œë¹„ìŠ¤_B0M' # ì•…ì„±ë¶€ì±„1\n",
    "COL_CARD_LOAN = 'ì”ì•¡_ì¹´ë“œë¡ _B0M'    # ì•…ì„±ë¶€ì±„2\n",
    "COL_DELINQ = 'ì—°ì²´ì”ì•¡_B0M'          # ë¦¬ìŠ¤í¬3\n",
    "COL_AVG_BAL = 'ì›”ì¤‘í‰ì”'             # ìì‚°\n",
    "\n",
    "def calc_slope_long(series):\n",
    "    \"\"\"ì‹œê³„ì—´ ë°ì´í„°(Series)ì˜ ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°\"\"\"\n",
    "    y = series.values.astype(float)\n",
    "    if len(y) < 2 or np.sum(y) == 0:\n",
    "        return 0\n",
    "    x = np.arange(len(y))\n",
    "    slope, _, _, _, _ = linregress(x, y)\n",
    "    return 0 if np.isnan(slope) else slope\n",
    "\n",
    "# Additional columns for R12M fallback\n",
    "COL_SPEND_R12M = 'ì´ìš©ê¸ˆì•¡_ì‹ ìš©_R12M'\n",
    "COL_COUNT_R12M = 'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_R12M'\n",
    "\n",
    "def calculate_churn_scores(group):\n",
    "    \"\"\"ê³ ê° í•œ ëª…ì˜ ë°ì´í„°ë¥¼ ë°›ì•„ ì ìˆ˜ ë° Target ìƒì„± (1ê°œì›” ì´ìƒ ë°ì´í„° í•„ìš”)\"\"\"\n",
    "    # ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš°\n",
    "    if len(group) < 1:\n",
    "        return pd.Series({\n",
    "            'Score_BadDebt': 0, 'Score_Delinq': 0, 'Score_Activity': 0, 'Score_Asset': 0,\n",
    "            'Score_Status_Total': 0, 'Slope_Spend': 0, 'Slope_Balance': 0, 'Slope_Count': 0\n",
    "        })\n",
    "\n",
    "    # (A) ìƒíƒœ ì ìˆ˜ (Status Score) ì„¸ë¶€ í•­ëª© ê³„ì‚°\n",
    "    try:\n",
    "        # Helper for safe indexing\n",
    "        def get_val(col, idx_from_last):\n",
    "            # idx_from_last: 1 for last, 2 for 2nd last...\n",
    "            if len(group) >= idx_from_last:\n",
    "                return group[col].iloc[-idx_from_last]\n",
    "            return 0\n",
    "\n",
    "        # 1. [ë¶€ì •] ì•…ì„± ë¶€ì±„ ì ìˆ˜ (Score_BadDebt)\n",
    "        # If only 1 month, cannot compare with previous, so score is 0\n",
    "        val_last = get_val(COL_CASH_ADV, 1)\n",
    "        val_prev = get_val(COL_CASH_ADV, 2)\n",
    "        \n",
    "        loan_last = get_val(COL_CARD_LOAN, 1)\n",
    "        loan_prev = get_val(COL_CARD_LOAN, 2)\n",
    "        \n",
    "        bad_debt_score = (\n",
    "            ((val_last - val_prev) / (val_prev + 1) * 1.5) +\n",
    "            ((loan_last - loan_prev) / (loan_prev + 1) * 1.0)\n",
    "        )\n",
    "        \n",
    "        # 2. [ë¶€ì •] ì—°ì²´ ê°•ë„ ì ìˆ˜ (Score_Delinq)\n",
    "        delinq_score = (get_val(COL_DELINQ, 1) * 3.0) + (get_val(COL_DELINQ, 2) * 2.0)\n",
    "        if len(group) >= 3:\n",
    "            delinq_score += (get_val(COL_DELINQ, 3) * 1.0)\n",
    "        \n",
    "        # 3. [ê¸ì •] í™œë™ì„± ì ìˆ˜ (Score_Activity)\n",
    "        sum_r3 = group[COL_COUNT].iloc[-3:].sum()\n",
    "        sum_r6 = group[COL_COUNT].sum()\n",
    "        activity_score = ((sum_r3 * 2) - sum_r6) / (sum_r6 + 1) * 100\n",
    "        \n",
    "        # 4. [ê¸ì •] ìì‚° ë°©ì–´ ì ìˆ˜ (Score_Asset)\n",
    "        avg_r3 = group[COL_AVG_BAL].iloc[-3:].mean()\n",
    "        avg_r6 = group[COL_AVG_BAL].mean()\n",
    "        asset_score = (avg_r3 / (avg_r6 + 1)) * 10\n",
    "        \n",
    "        # >> [Total] ìƒíƒœ ì¢…í•© ì ìˆ˜ (Score_Status_Total)\n",
    "        score_status_total = (bad_debt_score + delinq_score) - (activity_score + asset_score)\n",
    "    except:\n",
    "        bad_debt_score = 0\n",
    "        delinq_score = 0\n",
    "        activity_score = 0\n",
    "        asset_score = 0\n",
    "        score_status_total = 0\n",
    "\n",
    "    # (B) ê¸°ìš¸ê¸° ì ìˆ˜ (Slope Score)\n",
    "    # CASE 1: Data >= 2 months (Use linregress)\n",
    "    if len(group) >= 2:\n",
    "        slope_spend = calc_slope_long(group[COL_SPEND])\n",
    "        slope_balance = calc_slope_long(group[COL_BALANCE])\n",
    "        slope_count = calc_slope_long(group[COL_COUNT])\n",
    "    \n",
    "    # CASE 2: Data == 1 month (Use R12M fallback)\n",
    "    else:\n",
    "        # Spending Slope Proxy: Current - Monthly_Avg(R12M)\n",
    "        # If current < avg, result is negative (decrease) -> Condition met\n",
    "        # If current > avg, result is positive (increase) -> Condition failed\n",
    "        r12m_spend = group[COL_SPEND_R12M].iloc[0] if COL_SPEND_R12M in group.columns else 0\n",
    "        avg_spend = r12m_spend / 12\n",
    "        slope_spend = group[COL_SPEND].iloc[0] - avg_spend\n",
    "        \n",
    "        # Count Slope Proxy\n",
    "        r12m_count = group[COL_COUNT_R12M].iloc[0] if COL_COUNT_R12M in group.columns else 0\n",
    "        avg_count = r12m_count / 12\n",
    "        slope_count = group[COL_COUNT].iloc[0] - avg_count\n",
    "        \n",
    "        # Balance Slope: User requested to exclude this (always satisfy).\n",
    "        # We set it to -1 (or any value <= 0) to ensure the condition (slope <= 0) passes.\n",
    "        slope_balance = -1\n",
    "\n",
    "    return pd.Series({\n",
    "        'Score_BadDebt': bad_debt_score,\n",
    "        'Score_Delinq': delinq_score,\n",
    "        'Score_Activity': activity_score,\n",
    "        'Score_Asset': asset_score,\n",
    "        'Score_Status_Total': score_status_total,\n",
    "        'Slope_Spend': slope_spend,\n",
    "        'Slope_Balance': slope_balance,\n",
    "        'Slope_Count': slope_count\n",
    "    })\n",
    "\n",
    "def check_churn_condition(scores):\n",
    "    \"\"\"Calculates Target (1 or 0) from scores series\"\"\"\n",
    "    # (ì¡°ê±´ A) ê¸°ìš¸ê¸° 3ì¢…(ì†Œë¹„, ì”ì•¡, ê±´ìˆ˜)ì´ ëª¨ë‘ 0 ì´í•˜\n",
    "    cond_slopes_decrease = (\n",
    "        (scores['Slope_Spend'] <= 0) & \n",
    "        (scores['Slope_Balance'] <= 0) & \n",
    "        (scores['Slope_Count'] <= 0)\n",
    "    )\n",
    "    \n",
    "    # (ì¡°ê±´ B) 4ëŒ€ ìœ„í—˜ ì§•í›„ ì¤‘ 1ê°œ ì´ìƒ ê°ì§€ (Risk_Count >= 1)\n",
    "    cond1 = scores['Score_BadDebt'] > 0\n",
    "    cond2 = scores['Score_Delinq'] > 0\n",
    "    cond3 = scores['Score_Activity'] < 0\n",
    "    cond4 = scores['Score_Asset'] == 0\n",
    "    \n",
    "    risk_count = int(cond1) + int(cond2) + int(cond3) + int(cond4)\n",
    "    cond_high_risk = (risk_count >= 1)\n",
    "    \n",
    "    return 1 if (cond_slopes_decrease and cond_high_risk) else 0\n",
    "\n",
    "def analyze_rolling_churn(file_path):\n",
    "    print(f\"\\n[Info] íŒŒì¼ ë¡œë“œ ë° ë¶„ì„ ì‹œì‘: {file_path}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        # Fill missing cols with 0 if needed\n",
    "        # Added R12M columns to required list\n",
    "        required_cols = [\n",
    "            COL_ID, COL_DATE, COL_SPEND, COL_COUNT, COL_BALANCE, \n",
    "            COL_CASH_ADV, COL_CARD_LOAN, COL_DELINQ, COL_AVG_BAL,\n",
    "            COL_SPEND_R12M, COL_COUNT_R12M\n",
    "        ]\n",
    "        for c in required_cols:\n",
    "            if c not in df.columns: df[c] = 0\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "\n",
    "    # Sort\n",
    "    df.sort_values(by=[COL_ID, COL_DATE], inplace=True)\n",
    "    \n",
    "    # Group by ID\n",
    "    grouped = df.groupby(COL_ID)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\" - ê³ ê°ë³„ Rolling Analysis ì§„í–‰ ì¤‘... (ë°ì´í„° ìµœì†Œ 1ê°œì›” ê¸°ì¤€, 1ê°œì›” ì‹œ R12M ë³´ì™„)\")\n",
    "    \n",
    "    count_churners = 0\n",
    "    total_processed = 0\n",
    "    \n",
    "    for cust_id, group in grouped:\n",
    "        total_processed += 1\n",
    "        # Minimum 1 months required logic now supported\n",
    "        if len(group) < 1:\n",
    "            continue\n",
    "            \n",
    "        # 1. \"í˜„ì¬ ì‹œì \"ì˜ ì´íƒˆ ì—¬ë¶€ë¥¼ í™•ì¸\n",
    "        # (ì£¼ì˜: ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²ƒì€ 'í˜„ì¬ ì´íƒˆìì¸ ì‚¬ëŒ'ì˜ ê³¼ê±° ì§€ì†ê¸°ê°„ í™•ì¸ì´ë¯€ë¡œ,\n",
    "        # ê°€ì¥ ë§ˆì§€ë§‰ ë‹¬ì´ Churnì´ì–´ì•¼ ë¶„ì„ ëŒ€ìƒì´ ë¨)\n",
    "        current_scores = calculate_churn_scores(group)\n",
    "        is_current_churn = check_churn_condition(current_scores)\n",
    "        \n",
    "        if is_current_churn == 1:\n",
    "            count_churners += 1\n",
    "            \n",
    "            # 2. ì´íƒˆìë¼ë©´, ê³¼ê±°ë¡œ ì—­ì¶”ì  (Rolling)\n",
    "            consecutive_months = 1 # Start with 1 (the current month)\n",
    "            \n",
    "            # Max lookback\n",
    "            # If len=6, loops i=1 to 5 (check len=5 down to len=1)\n",
    "            # If len=1, loop range(1, 1) -> Empty loop (correct, duration=1)\n",
    "            max_lookback = len(group) - 1\n",
    "            \n",
    "            for i in range(1, max_lookback + 1):\n",
    "                past_group = group.iloc[:-i] # Remove last i rows\n",
    "                past_scores = calculate_churn_scores(past_group)\n",
    "                is_past_churn = check_churn_condition(past_scores)\n",
    "                \n",
    "                if is_past_churn == 1:\n",
    "                    consecutive_months += 1\n",
    "                else:\n",
    "                    break # Break chain\n",
    "            \n",
    "            results.append({\n",
    "                'Cust_ID': cust_id,\n",
    "                'Churn_Duration_Months': consecutive_months\n",
    "            })\n",
    "            \n",
    "        # if total_processed % 1000 == 0:\n",
    "        #     print(f\"   ... {total_processed}ëª… ì²˜ë¦¬ ì™„ë£Œ (ë°œê²¬ëœ ì´íƒˆì: {count_churners}ëª…)\")\n",
    "\n",
    "    # Output Results\n",
    "    if len(results) == 0:\n",
    "        print(\"âŒ ë¶„ì„ëœ ì´íƒˆìê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    df_res = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ“Š ì´íƒˆì Rolling ë¶„ì„ ê²°ê³¼ (ëŒ€ìƒ íŒŒì¼: {os.path.basename(file_path)})\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\" - ì´ ë¶„ì„ ê³ ê° ìˆ˜: {total_processed}ëª…\")\n",
    "    print(f\" - ìµœì¢… ì‹œì  ì´íƒˆì ìˆ˜: {len(df_res)}ëª… ({len(df_res)/total_processed*100:.2f}%)\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\" [ì´íƒˆ ì§•í›„ ì§€ì† ê¸°ê°„ í†µê³„]\")\n",
    "    print(df_res['Churn_Duration_Months'].describe())\n",
    "    print(\"-\" * 30)\n",
    "    print(\" [ê¸°ê°„ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)]\")\n",
    "    print(df_res['Churn_Duration_Months'].value_counts().sort_index(ascending=False).head(10))\n",
    "    \n",
    "    # Save detailed results\n",
    "    save_path = f\"churn_duration_results_{os.path.basename(file_path)}\"\n",
    "    # df_res.to_csv(save_path, index=False)\n",
    "    print(f\"\\nâœ… ìƒì„¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE = '../../../260108/general_combined_part1.csv'\n",
    "analyze_rolling_churn(TEST_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
