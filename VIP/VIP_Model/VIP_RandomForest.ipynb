{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd231c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13159e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FILE_PATH] ../../DATA/VIP/VIP_combined_part0.csv\n",
      "[ì¡´ì¬ ì—¬ë¶€] True\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0) ì…ë ¥ íŒŒì¼ ê²½ë¡œ (part0 ê³ ì •)\n",
    "# ============================\n",
    "# ê¸°ì¡´ ë…¸íŠ¸ë¶ì´ part1ì„ ì“°ê³  ìˆì—ˆë‹¤ë©´, ì—¬ê¸°ì„œ part0ë¡œ ë°”ê¾¼ ìƒíƒœì…ë‹ˆë‹¤.\n",
    "FILE_PATH = '../../DATA/VIP/VIP_combined_part0.csv'\n",
    "\n",
    "print(\"[FILE_PATH]\", FILE_PATH)\n",
    "print(\"[ì¡´ì¬ ì—¬ë¶€]\", os.path.exists(FILE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51c957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë¡œë“œ ì„±ê³µ] shape = (600000, 891)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1) ë°ì´í„° ë¡œë“œ (ì—ëŸ¬ ë°©ì–´)\n",
    "# ============================\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        print(\"[ë¡œë“œ ì„±ê³µ] shape =\", df.shape)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"âŒ [ë¡œë“œ ì‹¤íŒ¨]\", e)\n",
    "        return None\n",
    "\n",
    "df = safe_read_csv(FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d708b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“Š íƒ€ê²Ÿ ìƒì„± ê²°ê³¼ (Method B: 20% ê°ì†Œ ë£°)\n",
      "==================================================\n",
      " - ì „ì²´ ë°ì´í„°: 600000ê±´\n",
      " - í•™ìŠµìš© ë°ì´í„°(0/1): 579533ê±´\n",
      "   â”” ì´íƒˆ(1): 46802ê±´ (8.08%)\n",
      "   â”” ìœ ì§€(0): 532731ê±´\n",
      " - íŒë‹¨ ì œì™¸(NaN): 20467ê±´\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 2) VIP íƒ€ê²Ÿ ìƒì„± (Method B: 20% ê°ì†Œ ë£°)\n",
    "#    - Target = 1 (ì´íƒˆ): ë‹¹ì›” ì´ ì´ìš©ê¸ˆì•¡ < (ì§ì „ 3ê°œì›” í‰ê·  * 0.8)\n",
    "#    - Target = 0 (ìœ ì§€): ê·¸ ì™¸\n",
    "#    - íŒë‹¨ ì œì™¸(NaN): ì§ì „ 3ê°œì›” í‰ê· ì´ 0/ê²°ì¸¡ì¸ ê²½ìš°(íœ´ë©´/ì‹ ê·œ)\n",
    "# ============================\n",
    "def generate_target_method_b(df, ratio_threshold=0.8):\n",
    "    if df is None:\n",
    "        return None, None\n",
    "\n",
    "    required_cols = [\n",
    "        \"ë°œê¸‰íšŒì›ë²ˆí˜¸\", \"ê¸°ì¤€ë…„ì›”\",\n",
    "        \"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M\", \"ì´ìš©ê¸ˆì•¡_ì²´í¬_B0M\",\n",
    "        \"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_R3M\", \"ì´ìš©ê¸ˆì•¡_ì²´í¬_R3M\",\n",
    "    ]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if len(missing) > 0:\n",
    "        print(\"âŒ [íƒ€ê²Ÿ ìƒì„± ì‹¤íŒ¨] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½:\", missing)\n",
    "        return None, None\n",
    "\n",
    "    work = df.copy()\n",
    "\n",
    "    # ì •ë ¬(íšŒì›/ì›” ê¸°ì¤€) â€” ì›ë³¸ ì˜ë„ ìœ ì§€\n",
    "    try:\n",
    "        work = work.sort_values(by=[\"ë°œê¸‰íšŒì›ë²ˆí˜¸\", \"ê¸°ì¤€ë…„ì›”\"]).copy()\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ [ì •ë ¬ ê²½ê³ ] ì •ë ¬ ì‹¤íŒ¨:\", e)\n",
    "\n",
    "    # ê²°ì¸¡ 0 ì²˜ë¦¬(íƒ€ê²Ÿ ìƒì„±ìš© ì»¬ëŸ¼ë§Œ)\n",
    "    for c in [\"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M\", \"ì´ìš©ê¸ˆì•¡_ì²´í¬_B0M\", \"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_R3M\", \"ì´ìš©ê¸ˆì•¡_ì²´í¬_R3M\"]:\n",
    "        work[c] = work[c].fillna(0)\n",
    "\n",
    "    # ë‹¹ì›”/ì§ì „3M í‰ê·  ì‚°ì¶œ\n",
    "    work[\"ë‹¹ì›”_ì´_ì´ìš©ê¸ˆì•¡\"] = work[\"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M\"] + work[\"ì´ìš©ê¸ˆì•¡_ì²´í¬_B0M\"]\n",
    "    work[\"ì§ì „_3M_í‰ê· _ì´ìš©ê¸ˆì•¡\"] = (work[\"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_R3M\"] + work[\"ì´ìš©ê¸ˆì•¡_ì²´í¬_R3M\"]) / 3\n",
    "\n",
    "    # Target ì´ˆê¸°í™”\n",
    "    work[\"Target\"] = np.nan\n",
    "\n",
    "    # íŒë‹¨ ê°€ëŠ¥ ì¡°ê±´: ì§ì „ 3M í‰ê·  > 0\n",
    "    can_judge = work[\"ì§ì „_3M_í‰ê· _ì´ìš©ê¸ˆì•¡\"] > 0\n",
    "\n",
    "    # ë¹„ìœ¨ ê³„ì‚° ë° íƒ€ê²Ÿ ë¶€ì—¬\n",
    "    ratio = pd.Series(np.nan, index=work.index)\n",
    "    ratio.loc[can_judge] = work.loc[can_judge, \"ë‹¹ì›”_ì´_ì´ìš©ê¸ˆì•¡\"] / work.loc[can_judge, \"ì§ì „_3M_í‰ê· _ì´ìš©ê¸ˆì•¡\"]\n",
    "\n",
    "    work.loc[can_judge & (ratio < ratio_threshold), \"Target\"] = 1\n",
    "    work.loc[can_judge & (ratio >= ratio_threshold), \"Target\"] = 0\n",
    "\n",
    "    train_df = work[work[\"Target\"].notna()].copy()\n",
    "    train_df[\"Target\"] = train_df[\"Target\"].astype(int)\n",
    "\n",
    "    dormant_df = work[work[\"Target\"].isna()].copy()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ“Š íƒ€ê²Ÿ ìƒì„± ê²°ê³¼ (Method B: 20% ê°ì†Œ ë£°)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\" - ì „ì²´ ë°ì´í„°: {len(work)}ê±´\")\n",
    "    print(f\" - í•™ìŠµìš© ë°ì´í„°(0/1): {len(train_df)}ê±´\")\n",
    "    if len(train_df) > 0:\n",
    "        print(f\"   â”” ì´íƒˆ(1): {(train_df['Target']==1).sum()}ê±´ ({train_df['Target'].mean()*100:.2f}%)\")\n",
    "        print(f\"   â”” ìœ ì§€(0): {(train_df['Target']==0).sum()}ê±´\")\n",
    "    print(f\" - íŒë‹¨ ì œì™¸(NaN): {len(dormant_df)}ê±´\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return train_df, dormant_df\n",
    "\n",
    "train_data, dormant_data = generate_target_method_b(df, ratio_threshold=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eef5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ê·¸ë£¹ ëˆ„ìˆ˜ ì²´í¬] ê²¹ì¹˜ëŠ” íšŒì› ìˆ˜ = 0\n",
      "\n",
      "[ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ]\n",
      " - X_train: (463529, 697)  y_train: (463529,)  (ì´íƒˆë¹„ì¤‘: 0.0809 )\n",
      " - X_test : (116004, 697)  y_test : (116004,)  (ì´íƒˆë¹„ì¤‘: 0.0801 )\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 3) ëª¨ë¸ ì…ë ¥ ë°ì´í„° êµ¬ì„± (ëˆ„ìˆ˜ ì œê±° + ë°œê¸‰íšŒì›ë²ˆí˜¸ ê¸°ì¤€ ë¶„ë¦¬)\n",
    "# ============================\n",
    "def prepare_Xy_group_split(\n",
    "    train_df,\n",
    "    id_col=\"ë°œê¸‰íšŒì›ë²ˆí˜¸\",\n",
    "    target_col=\"Target\",\n",
    "    drop_b0m=True\n",
    "):\n",
    "    if train_df is None or len(train_df) == 0:\n",
    "        print(\"âŒ [ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨] í•™ìŠµìš© train_dfê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    if id_col not in train_df.columns or target_col not in train_df.columns:\n",
    "        print(\"âŒ [ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½:\", id_col, target_col)\n",
    "        return None, None, None, None\n",
    "\n",
    "    data = train_df.copy()\n",
    "\n",
    "    # íƒ€ê²Ÿ ìƒì„±ì— ì‚¬ìš©ëœ ì»¬ëŸ¼(ëˆ„ìˆ˜ ê°€ëŠ¥) ì œê±°\n",
    "    leakage_cols = [\n",
    "        \"ë‹¹ì›”_ì´_ì´ìš©ê¸ˆì•¡\", \"ì§ì „_3M_í‰ê· _ì´ìš©ê¸ˆì•¡\",\n",
    "        \"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_B0M\", \"ì´ìš©ê¸ˆì•¡_ì²´í¬_B0M\",\n",
    "        \"ì´ìš©ê¸ˆì•¡_ì‹ ìš©_R3M\", \"ì´ìš©ê¸ˆì•¡_ì²´í¬_R3M\",\n",
    "    ]\n",
    "\n",
    "    # B0M í¬í•¨ ì»¬ëŸ¼ì€ ë‹¹ì›” ì •ë³´ì´ë¯€ë¡œ í†µì§¸ë¡œ ì œê±°(ì›ë³¸ ì˜ë„)\n",
    "    b0m_cols = []\n",
    "    if drop_b0m:\n",
    "        b0m_cols = [c for c in data.columns if \"B0M\" in c]\n",
    "\n",
    "    drop_cols = list(set([id_col, \"ê¸°ì¤€ë…„ì›”\", target_col] + leakage_cols + b0m_cols))\n",
    "    drop_cols_exist = [c for c in drop_cols if c in data.columns]\n",
    "\n",
    "    X = data.drop(columns=drop_cols_exist, errors=\"ignore\").copy()\n",
    "    y = data[target_col].astype(int).copy()\n",
    "\n",
    "    # íšŒì› ë‹¨ìœ„ë¡œ stratify (íšŒì›ë³„ target 1ê°œë§Œ ì¶”ì¶œ)\n",
    "    unique_ids = data[[id_col, target_col]].drop_duplicates(subset=[id_col]).copy()\n",
    "    try:\n",
    "        train_ids, test_ids = train_test_split(\n",
    "            unique_ids[id_col],\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=unique_ids[target_col]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # stratify ë¶ˆê°€ëŠ¥(ì†Œìˆ˜ í´ë˜ìŠ¤ê°€ ë„ˆë¬´ ì ê±°ë‚˜ ë“±) ì‹œ fallback\n",
    "        print(\"âš ï¸ stratify split ì‹¤íŒ¨ â†’ ë¹„ì¸µí™” splitë¡œ ëŒ€ì²´:\", e)\n",
    "        train_ids, test_ids = train_test_split(\n",
    "            unique_ids[id_col],\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    train_mask = data[id_col].isin(train_ids)\n",
    "    test_mask = data[id_col].isin(test_ids)\n",
    "\n",
    "    X_train = X.loc[train_mask].copy()\n",
    "    y_train = y.loc[train_mask].copy()\n",
    "    X_test = X.loc[test_mask].copy()\n",
    "    y_test = y.loc[test_mask].copy()\n",
    "\n",
    "    # ê·¸ë£¹ ëˆ„ìˆ˜ ì²´í¬\n",
    "    overlap = set(data.loc[train_mask, id_col]).intersection(set(data.loc[test_mask, id_col]))\n",
    "    print(\"[ê·¸ë£¹ ëˆ„ìˆ˜ ì²´í¬] ê²¹ì¹˜ëŠ” íšŒì› ìˆ˜ =\", len(overlap))\n",
    "\n",
    "    print(\"\\n[ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ]\")\n",
    "    print(\" - X_train:\", X_train.shape, \" y_train:\", y_train.shape, \" (ì´íƒˆë¹„ì¤‘:\", round(y_train.mean(), 4), \")\")\n",
    "    print(\" - X_test :\", X_test.shape,  \" y_test :\", y_test.shape,  \" (ì´íƒˆë¹„ì¤‘:\", round(y_test.mean(), 4), \")\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_Xy_group_split(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "569583b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¸ì½”ë”©/ê²°ì¸¡ ì²˜ë¦¬ ì™„ë£Œ] X_train: (463529, 697) X_test: (116004, 697)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 4) ë²”ì£¼í˜• ì²˜ë¦¬(LabelEncoder) + ê²°ì¸¡ ì²˜ë¦¬\n",
    "# ============================\n",
    "def encode_and_fillna(X_train, X_test):\n",
    "    if X_train is None:\n",
    "        return None, None\n",
    "\n",
    "    Xtr = X_train.copy()\n",
    "    Xte = X_test.copy()\n",
    "\n",
    "    cat_cols = Xtr.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            le = LabelEncoder()\n",
    "            full = pd.concat([Xtr[col], Xte[col]], axis=0).astype(str)\n",
    "            le.fit(full)\n",
    "            Xtr[col] = le.transform(Xtr[col].astype(str))\n",
    "            Xte[col] = le.transform(Xte[col].astype(str))\n",
    "        except Exception as e:\n",
    "            # í•´ë‹¹ ì»¬ëŸ¼ì—ì„œ ì¸ì½”ë”©ì´ ë¬¸ì œê°€ ë‚˜ë©´ ê³¼ê°íˆ ì œê±°(ì—ëŸ¬ ë°©ì§€)\n",
    "            print(f\"âš ï¸ [ì¸ì½”ë”© ì‹¤íŒ¨] ì»¬ëŸ¼ ì œê±°: {col} / ì‚¬ìœ : {e}\")\n",
    "            Xtr = Xtr.drop(columns=[col], errors=\"ignore\")\n",
    "            Xte = Xte.drop(columns=[col], errors=\"ignore\")\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "    Xtr = Xtr.fillna(-999)\n",
    "    Xte = Xte.fillna(-999)\n",
    "\n",
    "    print(\"[ì¸ì½”ë”©/ê²°ì¸¡ ì²˜ë¦¬ ì™„ë£Œ] X_train:\", Xtr.shape, \"X_test:\", Xte.shape)\n",
    "    return Xtr, Xte\n",
    "\n",
    "X_train_enc, X_test_enc = encode_and_fillna(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2e37ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     45\u001b[39m     result = {\n\u001b[32m     46\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m     47\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_proba\u001b[39m\u001b[33m\"\u001b[39m: proba,\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m\"\u001b[39m: auc,\n\u001b[32m     54\u001b[39m     }\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m res_rf = \u001b[43mrun_random_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mrun_random_forest\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test)\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     13\u001b[39m model = RandomForestClassifier(\n\u001b[32m     14\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m     15\u001b[39m     max_depth=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     class_weight=\u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m proba = model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     27\u001b[39m pred = (proba >= \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 5) RandomForest í•™ìŠµ + í‰ê°€ (RFë§Œ)\n",
    "# ============================\n",
    "def run_random_forest(X_train, X_test, y_train, y_test):\n",
    "    if X_train is None or X_test is None:\n",
    "        print(\"âŒ [RF ì‹¤í–‰ ë¶ˆê°€] ì…ë ¥ ë°ì´í„°ê°€ None ì…ë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        print(\"âŒ [RF ì‹¤í–‰ ë¶ˆê°€] y_trainì— í´ë˜ìŠ¤ê°€ 1ê°œë¿ì…ë‹ˆë‹¤. (ì´íƒˆ/ìœ ì§€ ë‘˜ ë‹¤ ìˆì–´ì•¼ í•¨)\")\n",
    "        return None\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=None,\n",
    "        max_features=\"sqrt\",\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(\"\\n[RandomForest Confusion Matrix]\\n\", cm)\n",
    "\n",
    "    print(\"\\n[Classification Report]\")\n",
    "    print(classification_report(y_test, pred, digits=4))\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, proba)\n",
    "        print(\"[ROC-AUC] =\", round(auc, 4))\n",
    "    except Exception as e:\n",
    "        auc = None\n",
    "        print(\"âš ï¸ ROC-AUC ê³„ì‚° ì‹¤íŒ¨:\", e)\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "    print(f\"[ìš”ì•½] Precision={prec:.4f} | Recall={rec:.4f} | F1={f1:.4f} | AUC={auc}\")\n",
    "\n",
    "    result = {\n",
    "        \"model\": model,\n",
    "        \"y_proba\": proba,\n",
    "        \"y_pred\": pred,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "res_rf = run_random_forest(X_train_enc, X_test_enc, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ RF ê²°ê³¼ê°€ ì—†ì–´ì„œ Threshold íŠœë‹ì„ ìƒëµí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6) (ì„ íƒ) Threshold íŠœë‹ (Recall ì¤‘ì‹¬)\n",
    "# ============================\n",
    "if res_rf is None:\n",
    "    print(\"âš ï¸ RF ê²°ê³¼ê°€ ì—†ì–´ì„œ Threshold íŠœë‹ì„ ìƒëµí•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    proba = res_rf[\"y_proba\"]\n",
    "    thresholds = np.arange(0.05, 0.96, 0.05)\n",
    "\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "        rows.append([t, prec, rec, f1])\n",
    "\n",
    "    df_thr = pd.DataFrame(rows, columns=[\"threshold\", \"precision\", \"recall\", \"f1\"])\n",
    "    display(df_thr.sort_values(by=[\"recall\", \"precision\"], ascending=False).head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
